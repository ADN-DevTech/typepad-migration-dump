comments:
- author: Tony Tanzillo
  email: rebar@nym.hush.com
  ip: 24.187.155.159
  url: ''
  date: '2013-06-08 09:11:43'
  body: '"it does show one possible approach for mitigating some of the ergonomic
    issues the Leap Motion device presents"


    Hi Kean.


    What ergonomic issues are you referring to?'
- author: Kean Walmsley
  email: ''
  ip: 83.68.204.241
  url: http://profile.typepad.com/kean
  date: '2013-06-08 10:36:39'
  body: 'Hi Tony,


    The issues are mainly around hovering your hand in the air for any length of time:
    without support or haptic feedback this gets tiring very quickly.


    Kean'
- author: Kiwi
  email: ''
  ip: 76.14.71.6
  url: http://profile.typepad.com/kiwi1
  date: '2013-06-09 00:17:46'
  body: 'Hi Kean


    Great work with the concept. I would love to talk with you directly about this.
    Would you be able to contact me kiwi_at_leapmotion_com.'
- author: Tony Tanzillo
  email: rebar@nym.hush.com
  ip: 24.187.155.159
  url: ''
  date: '2013-06-09 22:13:05'
  body: "Hi Kean.  I don't think there are any issues with hovering your hand in the\
    \ air for any length of time, because with software that is designed for a device\
    \ like that, you wouldn't have to hover your hand in the air very long.\n\nThe\
    \ same holds true for haptic feedback.  Your ideas about how a device like the\
    \ Leap should work, are in terms of today's software, which was designed to work\
    \ primarily with 2D input.\n\nThe way it will eventually work (with 3D modeling\
    \ software at least), is that your hand will become just another 3D object in\
    \ the model, tracked in real time, and interference-checked with other nearby\
    \ objects in real time. You will see your hand in the model, and you will see\
    \ other model elements change appearance when your hand (or one or more fingers)\
    \ interferes with (e.g. 'touches') their volume. You will be able to reach into\
    \ the model, grab things, move/rotate them using your hand, and for precision,\
    \ there will be plenty of assistance from the software, not unlike the 2D drafting\
    \ aids we have now (objects snapping into place or aligning themselves or 'mating'\
    \ with other objects as they are being moved, etc).\n\nIMO, your point of view,\
    \ and what you perceive to be issues, are a product of your attempts to use the\
    \ Leap device as little more than a 3D digitizer. \n\nThe mouse on my desk has\
    \ a resolution of 1200 DPI, which makes it more sensitive than the Leap device,\
    \ and I would probably have the same issues with my mouse, if were to make the\
    \ mistake of trying to use it as a 2D digitizer, which isn't its primary purpose,\
    \ just as the Leap device's primary purpose is not to act as a 3D digitizer, which\
    \ up to this point, as you seem to think, based on your experiments and observations.\n\
    \nWhat is going to make the Leap device fundamentally change the way we interact\
    \ with computers, are the fundamental changes that will be required by software\
    \ (both at the system and application level) that will more easily allow it to\
    \ be used as a 3D input device, not merely as a 3D digitizer."
- author: Kean Walmsley
  email: ''
  ip: 83.68.204.241
  url: http://profile.typepad.com/kean
  date: '2013-06-10 03:27:39'
  body: 'Hi Tony,


    I partly agree.


    This particular avenue of research is certainly about retro-fitting this kind
    of input to a system that is designed around 2D input. My presentation at the
    Tech Summit - which will hopefully be accepted for AU 2013, in case you can make
    it - lists various options for integrating the technology, one of which would
    involve a more fundamental re-thinking of the software. That would clearly be
    the way to go to make optimal use of it, but is beyond the scope for near-term
    research.


    I did say "hover your hand for a certain length of time" in my previous comment,
    but that was written too quickly: this isn''t an issue that relates to the need
    to hold your hand steady above the device - which I agree is not the way to go
    for a usable integration - as much as it is about moving your hands freely in
    the air without support. I''d be interested in hearing your thoughts once you''ve
    spent some time using the controller: my own experience is that even playing Fruit
    Ninja gets tiring pretty quickly, as your hands just need to be a certain distance
    from the device for it to pick up movement.


    I believe this type of technology has an interesting future - it seems inevitable
    that someone is going come up with a gesture-based system that works really well,
    even for existing systems not specifically designed from the ground up with them
    in mind - but there are some hurdles that need to be overcome in the meantime.
    Itâ€™s definitely going to be interesting to see how the area evolves.


    Kean'
- author: Kean Walmsley
  email: ''
  ip: 83.68.204.241
  url: http://profile.typepad.com/kean
  date: '2013-06-10 03:28:21'
  body: 'Hi Kiwi,


    Would be happy to.


    Kean'
- author: Kean Walmsley
  email: ''
  ip: 83.68.204.241
  url: http://profile.typepad.com/kean
  date: '2013-06-10 12:11:39'
  body: 'I should probably add that I see some interesting "sweet spots" for this
    technology (just as there are for Kinect, although with some differences). They''d
    include the more "creative" design disciplines (clay sculpting, conceptual modeling,
    etc.), model navigation (collaborative or otherwise) and accessibility-related
    interactions. I''m sure there are others out there.


    Some of these relate to AutoCAD, but not all. Other people in the company are
    looking at integrating Leap Motion with other Autodesk products (I would think
    Maya, Navisworks and InfraWorks would be good choices, for instance), but I personally
    don''t expect it to revolutionize the way AutoCAD is used in the near-term.


    Then again, someone may well discover an approach that makes it work in a genuinely
    compelling way, which would be fantastic.


    Kean'
- author: James Maeding
  email: jmaeding@hunsaker.com
  ip: 24.249.247.46
  url: ''
  date: '2013-06-11 16:31:21'
  body: Wouldn't you also say the future involves spoken commands? Us humans seem
    to never tire of words, yet our hands get weary quickly for precise movements.
    I wonder how good current speach recognition is, as the dictation progs I have
    seen have a lag. So combine that with the 3d hand movement development under way,
    we are just at the beginning of better interface development. Similar to how civil
    engineering software is also just at its beginning.
- author: Kean Walmsley
  email: ''
  ip: 83.68.204.241
  url: http://profile.typepad.com/kean
  date: '2013-06-11 16:41:41'
  body: 'I''d certainly agree with that (although the people in the cubes next to
    me might not thank you ;-).


    If you want to add audio into your NUI, using Kinect certainly has the advantage
    of having a consistent approach for dealing with speech (although there''s clearly
    a trade-off with sensitivity... we''ll see if the next-gen Kinect delivers accurate
    finger-tracking or not).


    Kean

    -----'
