---
layout: "post"
title: "First impressions of the FARO Freestyle3D scanner"
date: "2015-04-10 20:17:59"
author: "Kean Walmsley"
categories:
  - "AutoCAD"
  - "Morgan"
  - "Point clouds"
  - "Reality capture"
original_url: "https://www.keanw.com/2015/04/first-impressions-of-the-faro-freestyle3d-scanner.html "
typepad_basename: "first-impressions-of-the-faro-freestyle3d-scanner"
typepad_status: "Publish"
---

<p>Back when FARO announced their new Freestyle3D handheld scanner, I contacted them to see whether they might have one for me to take a look at. They very kindly obliged, and a few weeks ago I received a loaner model in the post.</p>  <p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e201bb081a9884970d-pi"><img title="Boxed Freestyle3D" style="float: right; margin: 0px 0px 0px 20px; display: inline" alt="Boxed Freestyle3D" src="/assets/image_994588.jpg" width="175" align="right" height="312" /></a></p>  <p>I won’t be writing an exhaustive review – at least not in this post – but I did want to share my first impressions, mainly to capture them for future discussion. Bear in mind that most of what I’m writing here is personal opinion and the rest is pure speculation :-). Hopefully someone at FARO will be able to point out any factual inaccuracies so I can correct them.</p>  <p>Of course my primary interest in the scanner was to get it working in some way with AutoCAD, and ideally without a lot of the hurdles I jumped through when <a href="http://through-the-interface.typepad.com/through_the_interface/2014/08/autocad-integration-samples-for-kinect-for-windows-2-part-4.html" target="_blank">integrating Kinect Fusion</a> (in many ways a comparable system). Before seeing whether that was possible, let’s take a look at some of the important points about the Freestyle3D scanner.</p>  <p>Much like Kinect v1, the Freestyle3D is a <a href="http://en.wikipedia.org/wiki/Structured_light" target="_blank">structured light</a> scanner: it projects a pattern of infrared dots and detects their deformation. Like the first Kinect, it has a range of 50cm to 3m. That’s about where the similarities to Kinect end, though.</p>  <p>While Kinect Fusion requires a desktop class PC to run the Kinect runtime – essentially reconstructing a watertight 3D mesh in real(ish) time – the FARO system takes a different approach. More on this in a little while. One of the reasons Kinect Fusion has such heavyweight requirements is that it’s performing energy minimisation calculations between consecutive point-cloud frames – albeit in a highly parallellised fashion via the GPU – to determine what additional data is contributing to the mesh.</p>  <p>The Freestyle3D can work with any PC, but comes bundled with a <a href="http://www.microsoft.com/surface/en-us/products/surface-pro-3" target="_blank">Surface Pro 3</a> with FARO’s SCENE Capture software pre-installed. This is a great way to perform captures in an (largely) untethered way: there’s a wrist strap for the Surface Pro and you carry it around along with the scanner in your other hand (they are connected to each other by a USB 3 cable).</p>  <p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e201b7c776b67a970b-pi" target="_blank"><img title="Freestyle3D and Surface Pro 3" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin: 20px auto; border-left: 0px; display: block; padding-right: 0px" border="0" alt="Freestyle3D and Surface Pro 3" src="/assets/image_178149.jpg" width="394" height="223" /></a></p>  <p>[In many ways the Surface Pro 3 is the device of choice for many Windows-centric software vendors to meet the needs of mobile customers: Siemens seemed to base their whole mobile pitch around it at the recent <a href="http://www.develop3dlive.com/" target="_blank">Develop3D Live event</a>, for instance. It certainly has the horsepower to run moderately heavyweight desktop software without a significant amount of UI rework needed.]</p>  <p>So how is the Freestyle3D’s scanning approach different from Kinect Fusion? Rather than requiring a heavyweight graphics card to basically “diff” the point clouds for each frame coming from the scanner, SCENE Capture uses <a href="http://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping" target="_blank">Visual SLAM</a> to determine how the scanner is moving through space. It’s basically using computer vision to extract features – edges, corners, etc. – from the camera input and then uses these data-points to track how the scanner is moving through 3D space. You’ll notice, for instance, that tracking is very dependent on light levels: if there’s insufficient clarity in the image coming from the camera, the software has trouble extracting enough features and therefore tracking the scanner’s location.</p>  <p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e201bb081a9923970d-pi" target="_blank"><img title="Scanning a Morgan" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin: 20px auto; border-left: 0px; display: block; padding-right: 0px" border="0" alt="Scanning a Morgan" src="/assets/image_686030.jpg" width="394" height="264" /></a></p>  <p>This means a few things. Firstly, it’s a lot snappier: while you have to move slowly – and the software warns you when you’re starting to go too quickly – tracking is a lot more reliable than I was used to with Kinect Fusion. Secondly, you’re not working with a voxelised 3D volume – a closed mesh – you’re building a point cloud. Which means you’re going to see more noise, especially when scanning reflective surfaces, the Achilles heel of the 3D scanning world.</p>  <p>When tracking does get lost, the visual feedback is actually fairly good…<a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e201b7c776b6ed970b-pi" target="_blank"><img title="Tracking is lost" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin: 20px auto; border-left: 0px; display: block; padding-right: 0px" border="0" alt="Tracking is lost" src="/assets/image_66804.jpg" width="394" height="264" /></a></p>  <p>… you’re given decent visual clues as to where you need to place the scanner for tracking to be restored:</p>  <p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e201b7c776b715970b-pi" target="_blank"><img title="Time to reposition the scanner" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin: 20px auto; border-left: 0px; display: block; padding-right: 0px" border="0" alt="Time to reposition the scanner" src="/assets/image_42150.jpg" width="394" height="264" /></a></p>  <p>Capturing is therefore fairly painless. I’m by no means an expert user of SCENE, but I managed to work out most of what I needed. It apparently provides the capability to edit out erroneous frames from a scan – something I can see might be needed, as in a few of my longer scans I found that I had multiple planes for the floor or one of the walls. I’m sure this is down to user error, but it certainly highlights the fact you need a certain level of expertise to avoid this scenario (probably by creating and merging multiple, smaller scans).</p>  <p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e201bb081a9aaf970d-pi" target="_blank"><img title="The final point cloud" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin: 20px auto; border-left: 0px; display: block; padding-right: 0px" border="0" alt="The final point cloud" src="/assets/image_169933.jpg" width="394" height="264" /></a></p>          <p>One thing that absolutely needs work is the workflow from SCENE to Autodesk software. When you install SCENE you can see that it includes an Autodesk component called DeCap (this is an Autodesk SDK that can be used to create RCS and RCP files… it’s basically “headless” ReCap ;-). Unfortunately the SCENE software doesn’t seem to use this directly, at the time of writing (v5.4). I found I had to export to another format – whether .E57 or .PTX, sometimes one worked better than the other – and then import that into ReCap Studio to generate a .RCS or .RCP file that can be imported into AutoCAD.</p>  <p>So quite a convoluted process to get the data across from the Freestyle3D into AutoCAD. I’m told that both FARO and Autodesk are working on improving this workflow, so I don’t expect the pain to continue forever. It’s still early days, of course.</p>  <p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e201bb081a9aca970d-pi" target="_blank"><img title="Scanned Morgan" style="border-top: 0px; border-right: 0px; background-image: none; border-bottom: 0px; float: none; padding-top: 0px; padding-left: 0px; margin: 20px auto; border-left: 0px; display: block; padding-right: 0px" border="0" alt="Scanned Morgan" src="/assets/image_740508.jpg" width="394" height="238" /></a></p>  <p>I’d also love to see this scanner feed <a href="http://memento.autodesk.com" target="_blank">Autodesk Memento</a>, generating a mesh rather than a point cloud. This kind of integration is largely working with Artec’s scanners, today, but not yet with other devices such as the Freestyle3D.</p>  <p>Overall I found it very interesting working with the Freestyle3D. I’m very curious to see how this technology – and the supporting workflow – evolves, over time. I’m sadly having to ship it back in the next few days, but I have stored a fairly varied set of captures that I intend to work on, when I get the chance. For instance I fully intend to try extracting floorplans from an office space, as mentioned <a href="http://through-the-interface.typepad.com/through_the_interface/2015/04/autocad-2016-extracting-floorplans-from-point-clouds-using-net.html" target="_blank">the last post</a>.</p>
