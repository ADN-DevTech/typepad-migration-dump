---
layout: "post"
title: "Parallel operations in Dynamo and Refinery"
date: "2019-05-08 14:33:42"
author: "Kean Walmsley"
categories:
  - "Autodesk Research"
  - "Concurrent programming"
  - "Dynamo"
  - "Generative design"
original_url: "https://www.keanw.com/2019/05/parallel-operations-in-dynamo-and-refinery.html "
typepad_basename: "parallel-operations-in-dynamo-and-refinery"
typepad_status: "Publish"
---

<p>I’ve mentioned this topic a <a href="https://www.keanw.com/2019/04/revisiting-mars-for-au-london-2019.html" target="_blank">few</a> <a href="https://www.keanw.com/2019/04/displaying-metrics-for-the-mars-graph-inside-dynamo-and-refinery.html" target="_blank">times</a> in recent weeks, so it was really time to sit down and put pen to paper (or fingers to keyboard). This one was a lot of fun to dig into, and I think the results will be of interest to people.</p><p>Parallelism is something that I’ve been tracking since my studies during the 90s: I remember programming <a href="https://en.wikipedia.org/wiki/Transputer" target="_blank">transputers</a> using a programming language called <a href="https://en.wikipedia.org/wiki/Occam_(programming_language)" target="_blank">occam</a>, way back when. I was really happy when – around a decade ago – Microsoft got serious about tackling asynchrony and concurrency with F#’s Asynchronous Workflows and the .NET Framework’s Task Parallel Library. I had a lot of fun playing with both, <a href="https://www.keanw.com/concurrent_programming/" target="_blank">mostly in the context of AutoCAD programming</a>.</p><p>When my colleague Simon Breslav decided to try using Parallel.ForEach from IronPython code inside Dynamo, I was definitely intrigued, especially with respect to how that code would then work with Project Refinery.</p><p>Firstly, let’s discuss what Parallel.ForEach does, and how to use it inside Dynamo. Parallel.For and Parallel.ForEach basically step through a set of operations in much the same way as standard for/foreach loops do, but rather than executing each iteration synchronously, they create asynchronous tasks for each loop iteration that will then get executed by the .NET Framework via the CLR thread pool.</p><p>It’s a great way to parallelize code – as long as you pay attention to the <a href="https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/potential-pitfalls-in-data-and-task-parallelism" target="_blank">potential pitfalls</a> – which can improve performance significantly. Simon chose to use Parallel.ForEach to improve the performance of a number of the Project Rediscover metrics, notably for calculating Buzz, Visual Distraction and Daylight. I added a global toggle that allows us to switch easily between serial and parallel loop execution, so we can compare performance and work out whether it’s all worth the effort.</p><p>So how do you use Parallel.ForEach with Dynamo? The simplest way is to integrate it into Python code: as Dynamo runs Python code using IronPython – which has access to the .NET Framework – we can get access to it simply by importing the <font face="Courier New" size="2">System.Threading.Tasks</font> module.</p><p>Let’s take a look at the approach we’ve taken for the various metrics. Here’s the basic structure we’ve used throughout. Assume that the <font face="Courier New" size="2">parallel</font> variable is just a Boolean flag saying whether to use Parallel.ForEach or a standard for loop. <font face="Courier New" size="2">calculateScore()</font> is our worker function that will store the results in the results array at index <font face="Courier New" size="2">i</font>. We’re passing in a <font face="Courier New" size="2">pathLattice</font> (actually a spaceLattice), as our operations happen to be on Space Analysis paths. (You’ll be able to see the “final” version of this once we publish the Project Rediscover graph, sometime between now and AU London in June.)</p><p><font face="Courier New" size="2">from System.Threading.Tasks import *</font><p><font face="Courier New" size="2">…</font><p><font face="Courier New" size="2">if parallel:<br>&nbsp;&nbsp;&nbsp; Parallel.ForEach(paths, lambda path, state, i: calculateScore(path, i, pathLattice, results))<br>else:<br>&nbsp;&nbsp;&nbsp; for i, path in enumerate(paths):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; calculateScore(path, i, pathLattice, results)</font><p>This approach has worked fairly solidly for our various metrics, but there are definitely areas to consider (that relate to the above-linked pitfalls): when there’s a shared variable – such as an array of values that needs to be contributed to (say when we’re calculating congestion, which is based on the sum of data from multiple paths) – we need to control access to the variable using (for instance) a Monitor object.</p><p>Also, if we’re going to use geometry in our function – such as when we analyse daylight by firing rays from the sun positions to various locations in the building – then we need to be super-careful: Autodesk’s Shape Manager library is multi-threaded, but we need to make sure certain geometry is created and accessed from the same thread. We found raycasting to work well, but you would have to be very careful when creating surfaces, etc.</p><p>Does using Parallel.For[Each] make a big difference?</p><p>It depends on the way your code is structured and the characteristics of the execution environment. I tried a couple of different versions of the Project Rediscover graph, one which only calculates global daylight, while the other does much more, calculating daylight per-neighbourhood as well as teams’ workplace preference. I ran the calculations on two different systems: one inside a Parallels VM on my aging MacBook Pro (which has 4 cores dedicated to it) and a beefy, native Windows desktop with 16 cores and a shedload of RAM.</p><p>On the resource-constrained environment, I saw a modest increase in performance: the lighter model ran in 70 seconds in serial mode, and 54 seconds in parallel mode… so a 24% improvement. The heavier model went from 285 seconds in serial to 196 seconds in parallel. So a 31% improvement.</p><p>On the beefier system, we saw much more significant gains. The lighter model started at 45 seconds serially and dropped to 14 seconds in parallel. A whopping 69% improvement. And the heavier model went from 196 seconds to 41 seconds… an improvement of 79%!</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a45bbf22200c-pi" target="_blank"><img width="500" height="135" title="Dynamo numbers" style="margin: 30px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" alt="Dynamo numbers" src="/assets/image_910815.jpg" border="0"></a></p><p>This was really encouraging, but it’s worth bearing a few things in mind: .NET will use all available cores to run these additional tasks: if you check out the CPU usage when running the graph, you’ll see it go from around 25% utilization (on a quadcore system) to 100% utilization. As you might expect, the .NET Framework uses the CLR thread pool extremely efficiently.</p><p>Here are some screenshots taken during a serial run:</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a484ef52200d-pi" target="_blank"><img width="419" height="375" title="Dynamo - Task Manager processes - serial" style="margin: 30px auto; border-image: none; float: none; display: block; background-image: none;" alt="Dynamo - Task Manager processes - serial" src="/assets/image_112081.jpg" border="0"></a></p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a45bbf2c200c-pi" target="_blank"><img width="425" height="375" title="Dynamo - Task Manager CPU - serial" style="margin: 30px auto; border-image: none; float: none; display: block; background-image: none;" alt="Dynamo - Task Manager CPU - serial" src="/assets/image_258011.jpg" border="0"></a></p><p>And these are from a parallel run:</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a484ef57200d-pi" target="_blank"><img width="425" height="375" title="Dynamo - Task Manager processes - parallel" style="margin: 30px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" alt="Dynamo - Task Manager processes - parallel" src="/assets/image_400582.jpg" border="0"></a><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a45bbf26200c-pi" target="_blank"><img width="431" height="375" title="Dynamo - Task Manager CPU - parallel" style="margin: 30px auto; border-image: none; float: none; display: block; background-image: none;" alt="Dynamo - Task Manager CPU - parallel" src="/assets/image_47957.jpg" border="0"></a></p><p>Which is great, but what happens when it runs inside Refinery, which is in any case using process-level parallelism (running various instances of graph concurrently using separate executables)? Would it negate the gains? Would one graph execution consume all the CPU resources, leaving nothing for its siblings?</p><p>Looking at the CPU load during a serial run, at first glance it indeed seems there’s a more even processor utilization:</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a45bbf34200c-pi" target="_blank"><img width="415" height="375" title="Refinery - Task Manager CPU - serial" style="margin: 30px auto; border-image: none; float: none; display: block; background-image: none;" alt="Refinery - Task Manager CPU - serial" src="/assets/image_426863.jpg" border="0"></a></p><p>During a parallel run the processor utilization is heavier for four of the worker processes:</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a4a98a07200b-pi" target="_blank"><img width="435" height="375" title="Refinery - Task Manager processes - parallel" style="margin: 30px auto; border-image: none; float: none; display: block; background-image: none;" alt="Refinery - Task Manager processes - parallel" src="/assets/image_114210.jpg" border="0"></a></p><p>So this does suggest that the greedier resource usage of the parallel code is skewing things towards fewer worker executables. At some moments this becomes extreme:</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a484ef63200d-pi" target="_blank"><img width="434" height="375" title="Refinery - Task Manager processes - parallel - extreme" style="margin: 30px auto; border-image: none; float: none; display: block; background-image: none;" alt="Refinery - Task Manager processes - parallel - extreme" src="/assets/image_166155.jpg" border="0"></a></p><p>But how do things look in terms of execution time?</p><p>It turns out there’s still huge value in using Parallel.For even with Refinery. I did some tests with the heaviest model on the most performant of my two systems, and found that an optimization run of 5 generations of a population of 12 designs each went from 78 minutes (yes, minutes) execution time to just 26. So an improvement of 67%. This was consistent across 6 different runs (3 serial, 3 parallel) on my beefy desktop system. I didn’t do these tests on my Parallels VM as it’s prone to crashing (the VM, not Dynamo/Refinery) when pushed too far resource-wise.</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a484ef6b200d-pi" target="_blank"><img width="328" height="98" title="Refinery numbers" style="margin: 30px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" alt="Refinery numbers" src="/assets/image_571550.jpg" border="0"></a></p><p>Incidentally, there’s a really handy server log available at <em>%appdata%\Refinery\refinery-server-log.txt</em>, which avoids you having to measure the timing of runs individually.</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a45bbf3d200c-pi" target="_blank"><img width="389" height="375" title="Refinery server log" style="margin: 30px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" alt="Refinery server log" src="/assets/image_691050.jpg" border="0"></a></p><p>So this is really interesting… Here’s what I think is happening: Refinery’s server component appears to execute instances of the graph in groups of 4: it has more processes available, but for optimization runs they appear to be run in 4s. This is presumably related to the need to specify your population as a multiple of 4. I’ll check in with the Refinery team to understand what drives this – perhaps the way the optimisation process works? – or whether I’m mis-reading things. One possibility that the 4 that get launched when running in parallel initially consume most of the system resources, and then so 4 more don’t get launched immediately after, which is what happens when running serially.</p><p>Whatever the reason, there do appear to be resources left over that make the use of parallel code workflows worthwhile. I dusted off my grep and sed skills to dig into the Refinery server log, and found that the heavier graph was being executed in (on average) 298 seconds (serial) and 105 seconds (parallel). If you compare this with plain Dynamo Sandbox – which could take 100% of the CPU resources and ran in 196 and 41 seconds respectively – there’s clearly some performance impact with running in this way.</p><p><a href="https://through-the-interface.typepad.com/.a/6a00d83452464869e20240a45bbf41200c-pi" target="_blank"><img width="263" height="115" title="More Refinery numbers" style="margin: 30px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" alt="More Refinery numbers" src="/assets/image_901787.jpg" border="0"></a></p><p>I’m actually a little surprised the serial numbers weren’t more similar… going from 196 to 298 seconds (from running in the UI to running via Refinery), but then the average numbers were skewed slightly higher by runs that come towards the end of each study… sometimes these would weigh in at 11 or 12 minutes (660-720 seconds). This behaviour didn’t appear with the parallel runs, for some reason.</p><p>So, in a nutshell, using Parallel.For and Parallel.ForEach can be highly beneficial for graphs with complex calculations, whether just running in the Dynamo UI or being run by Refinery. The specific gains will depend on your system’s resources and how you use parallelism in your graph’s Python blocks.</p><p>The specific numbers I’ve shown today are for sure going to change, by the way: Project Rediscover is very much a work in progress, so the graph will a) be doing more and hopefully also b) be doing it more efficiently. Beyond that there are regular performance gains being delivered by both the Dynamo and Refinery teams.</p><p>A related note… measurement and optimisation (from a performance perspective, not in the Refinery sense of the word) is a big topic with Dynamo, at the moment. It was the driver behind one of the winning projects at the recent <a href="https://www.keanw.com/2019/05/presentations-and-awards-from-the-dynamo-and-generative-design-hackathon-in-london.html" target="_blank">Dynamo and Generative Design Hackathon in London</a>, and the Dynamo team are working on tools to make this easier, too.</p><p>Something else that’s worth noting is that the calculations in Dynamo graphs today are largely CPU-bound. One area Simon, Rhys and I have been discussing exploring is the ability to integrate operations that are calculated on the GPU. We’re very curious to find out what others have done in this space, so if you have any pointers, send them over! Right now we’re thinking it might be interesting to have Dynamo host <a href="https://en.wikipedia.org/wiki/OpenCL" target="_blank">OpenCL</a>, but that’s about as far as we’ve gotten, so far.</p>
