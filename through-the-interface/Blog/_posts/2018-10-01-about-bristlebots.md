---
layout: "post"
title: "About Bristlebots"
date: "2018-10-01 23:45:24"
author: "Kean Walmsley"
categories:
  - "APS (Forge)"
  - "Autodesk"
  - "Autodesk Research"
  - "Robotics"
original_url: "https://www.keanw.com/2018/10/about-bristlebots.html "
typepad_basename: "about-bristlebots"
typepad_status: "Publish"
---

<p>My world seems to be filled with robots, these days, whether seeing <a href="http://keanw.com/2018/09/robarch-2018.html" target="_blank">how they can be used in architecture and construction</a>, <a href="http://keanw.com/2018/09/animating-robots-in-the-forge-viewer.html" target="_blank">animating them inside Forge</a>, or seeing them <a href="http://www.keanw.com/2018/04/checking-out-the-worlds-first-3d-printed-steel-bridge-at-mx3d-in-amsterdam.html" target="_blank">3D print steel bridges</a> (I’m at MX3D again, this week). It makes me think I should probably dust off my HoloLens app for <a href="http://www.keanw.com/2016/08/making-our-hololens-robot-dance.html" target="_blank">making robots dance in mixed reality</a>: once we’re using data inside the Forge viewer-powered <a href="http://dasher360.com" target="_blank">Dasher 360</a> to show the position of a robot at a particular moment in time, it’s hardly a huge leap to show that in XR. Anyway, I should get to the point…</p><p>Given this current trend in my activities, it seemed a good time to talk about another project that piqued my interest recently. I met Evangelos (Evan) Pantazis briefly back when I visited <a href="https://iaac.net/" target="_blank">IaaC</a> during the <a href="http://www.keanw.com/2018/06/forge-accelerator-in-barcelona.html" target="_blank">Forge accelerator in Barcelona</a>. Evan delivered the 3rd presentation of the evening session at IaaC – the one we had to miss due to our dinner reservation – mentioned in the post I just linked to. Because the topic was so interesting to me Evan and I managed to find a time when both of us were available to talk about it (by this time Evan had found his way to LA, so this was harder than it might sound).</p><p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e2022ad3b549fd200b-pi" target="_blank"><img width="500" height="312" title="Bristlebots" style="margin: 30px auto; border: 0px currentcolor; border-image: none; float: none; display: block; background-image: none;" alt="Bristlebots" src="/assets/image_438203.jpg" border="0"></a></p><p>Evan has been doing some really interesting research into how emergent behaviours of swarms of relatively dumb robots – Bristlebots, which are typically <a href="https://www.hexbug.com/" target="_blank">Hexbugs</a> with minor mods – might be harnessed in construction. Evan did a portion of his research while resident at Autodesk Boston’s <a href="http://www.keanw.com/2016/09/toronto-and-boston.html" target="_blank">BUILDSpace</a>.</p><p>Here’s an intro video to the Bristlebot concept:</p><p align="center"><br></p><p align="center"><iframe width="500" height="281" src="https://player.vimeo.com/video/257330533?title=0&amp;byline=0&amp;portrait=0" frameborder="0" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen=""></iframe></p><p align="center"><br></p><p>This one looks at how Bristlebots perform in different environments:</p><p align="center"><br></p><p align="center"><iframe width="500" height="281" src="https://player.vimeo.com/video/257337351?title=0&amp;byline=0&amp;portrait=0" frameborder="0" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen=""></iframe></p><p align="center"><br></p><p>And this one looks at how computer vision can be used to detect positions of the Bristlebots on the ground from an overhead camera:</p><p align="center"><br></p><p align="center"><iframe width="500" height="281" src="https://player.vimeo.com/video/289007160?title=0&amp;byline=0&amp;portrait=0" frameborder="0" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen=""></iframe></p><p align="center"><br></p><p>This last one is especially relevant when considering how a central “intelligence” might be used to guide the bots in their work: this could be done using simple beams of light to “attract” the bots, or even encode more elaborate instructions (this is my speculation… I think Evan’s intention, overall, is not to have to build too many smarts into his bots ;-).</p><p>If you’re interested in learning more about Evan’s research, be sure to head on over to <a href="https://schemalab.usc.edu/about/" target="_blank">his research group’s page</a>. I’ll definitely be keeping tabs on what he gets up to!</p><p><strong><em>Update:</em></strong></p><p>Evan has provided an additional video that shows how you can use light to influence behaviour in the bots:</p><p align="center"><br></p><p align="center"><iframe width="500" height="281" src="https://player.vimeo.com/video/292864358?title=0&amp;byline=0&amp;portrait=0" frameborder="0" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen=""></iframe></p>
