---
layout: "post"
title: "BrickBot &ndash; an Autodesk Research project exploring the future of manufacturing"
date: "2018-08-15 19:39:17"
author: "Kean Walmsley"
categories:
  - "Autodesk"
  - "Autodesk Research"
  - "Machine Learning"
  - "Robotics"
original_url: "https://www.keanw.com/2018/08/brickbot-an-autodesk-research-project-exploring-the-future-of-manufacturing.html "
typepad_basename: "brickbot-an-autodesk-research-project-exploring-the-future-of-manufacturing"
typepad_status: "Publish"
---

<p><a href="http://through-the-interface.typepad.com/.a/6a00d83452464869e2022ad362f337200c-pi" rel="noopener noreferrer" target="_blank"><img alt="Brickbot" border="0" height="280" src="/assets/image_268942.jpg" style="margin: 30px auto; float: none; display: block; background-image: none;" title="Brickbot" width="500" /></a></p> <p>Last month <a href="https://www.fastcompany.com/90204615/autodesks-lego-model-building-robot-is-the-future-of-manufacturing" rel="noopener noreferrer" target="_blank">Fast Company published an article</a> about an interesting project <a href="http://autodeskresearch.com" rel="noopener noreferrer" target="_blank">Autodesk Research</a> has been working on for a number of years: internally the project was known as LEGOBot, but now that it’s being talked about publicly it has understandably been renamed to BrickBot.</p> <p style="text-align: center;"><br /></p> <center> <script src="//fast.wistia.com/assets/external/E-v1.js"></script> </center><center> <div class="wistia_embed wistia_async_96x2t5wu4m" style="width: 500px; height: 282px;"><br /></div> </center> <p style="text-align: center;"><br /></p> <p style="text-align: left;">BrickBot is a really cool project that’s built on two core ideas: robots are <strong>stupid</strong> and engineering is <strong>expensive</strong>. Robots need a lot of help to be told what to do, but telling them what to do is neither straightforward (today) nor flexible: you need to code for specific conditions, and if those conditions change you need to add more code.</p> <p>The over-arching goal of BrickBot is to build a system that takes a 3D model of something and then works out how to fabricate or assemble it. In this initial instance, BrickBot does this with LEGO bricks, but that’s just where things are today.</p> <p style="text-align: center;"><br /></p> <center> <script src="//fast.wistia.com/assets/external/E-v1.js"></script> </center><center> <div class="wistia_embed wistia_async_dscctlunnt" style="width: 500px; height: 282px;"> </div> </center> <p style="text-align: center;"><br /></p> <div style="text-align: left;">To be able to build a model from LEGO bricks – or anything, for that matter – there are three separate problems that need to be solved:</div> <div style="text-align: left;"> <ol> <li>Object detection and localization</li> <ul> <li>Looking at a bin of parts, what parts do we have and where are they?</li> </ul> <li>Grasping and manipulation of the bricks</li> <ul> <li>Knowing where the parts are, how do we go about picking them up and rotating them to be ready for placement?</li> </ul> <li>Planning, actuation and assessment</li> <ul> <li>Given the hierachy of the model – we need to build walls before the roof, for instance – what steps need to be taken when, and were they successful?</li> </ul> </ol> </div> <p style="text-align: left;">Back when Thomas Davies – a colleague based in Toronto – presented about the project at the internal <a href="http://www.keanw.com/2017/05/autodesk-technical-summit-2017.html" rel="noopener noreferrer" target="_blank">Autodesk Technical Summit 2017</a> (held in London), he mentioned they’d used 5 different <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener noreferrer" target="_blank">convolutional neural networks</a> to build their pipeline, with one feeding its results into the next. That was over a year ago, so the pipeline may well have grown since then.</p> <p style="text-align: left;">Another interesting part about the project is that the robots were trained in a purely virtual environment: synthetic images are generated with different lighting conditions and passed into the pipeline, removing the need to use real-world data and making it exponentially faster to train the system. Super cool!</p> <p style="text-align: left;">The story has been making the rounds over the last few weeks… even the <a href="https://www.bbc.co.uk/news/av/technology-45024268/lego-building-robot-aspires-to-bigger-things" rel="noopener noreferrer" target="_blank">BBC have featured it</a>. Here’s the video from the article:</p> <p style="text-align: left;"><br /></p> <p style="text-align: center;"><iframe frameborder="0" height="284" src="https://www.bbc.co.uk/news/av/embed/p06g6s34/45024268" width="500"></iframe></p> <p><br /></p> <p style="text-align: left;">I think this is a really promising project: this kind of capability is going to be extremely important in the future. Congratulations to Mike Haley, Yotto Koga and Thomas Davies for the well-deserved recognition of their work (even if Thomas is now off doing other things within the company).</p> <p style="text-align: left;">On a related note, I’m looking forward to visiting SINDEX at the end of the month (it’s a biennial event that I went to <a href="http://www.keanw.com/2014/09/sindex-2014.html" rel="noopener noreferrer" target="_blank">in 2014</a> and <a href="http://www.keanw.com/2016/09/sindex-16-cuddly-robots-are-the-future.html" rel="noopener noreferrer" target="_blank">in 2016</a>). Back in 2014 I saw some interesting approaches to solving the part picking problem, for instance: I’m curious to see who else is working on this kind of problem, and the kind of solutions that are being proposed.</p>
